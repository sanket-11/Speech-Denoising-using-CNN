{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Denoising using 2D CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dirty and clean audio files for training purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, sr=librosa.load(\"data/train_clean_male.wav\", sr=None)\n",
    "S=librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "sn, sr=librosa.load(\"data/train_dirty_male.wav\", sr=None)\n",
    "X=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "S_abs=np.abs(np.transpose(S))\n",
    "X_abs=np.abs(np.transpose(X))\n",
    "#X_abs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model architecture:\n",
    "\n",
    ">1st Conv2D layer is used with a filter of (18,2) and strides are (1,1) with relu activation and no padding.\n",
    "\n",
    ">2nd Conv2D layer is used with a filter of (3,12) and strides are (2,2) with relu activation and no padding.\n",
    "\n",
    ">Dropout of 0.1 and 0.2 is applied after each convolution layer respectively.\n",
    "\n",
    ">The flattened output after convolutions is fed into a dense layer with 1024 neurons.\n",
    "\n",
    ">>>I tried using many different combinations of kernel size but the outputs on tests weren't clear enough. It seemed logical since we're using 19 previous frames in each row and the network seems to learn the same frames over and over again with a small kernel size. Switching to a large kernel size seemed to do the trick and the output on the test files is clear with SNR >6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (?, 20, 513, 1)\n",
      "WARNING:tensorflow:From <ipython-input-3-3f45c8775166>:4: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\sanky\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x0000026ECDA7B390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x0000026ECDA7B390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x0000026ECDA7B390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x0000026ECDA7B390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "h1 (?, 3, 512, 50)\n",
      "WARNING:tensorflow:From <ipython-input-3-3f45c8775166>:7: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x0000026ECD657EB8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x0000026ECD657EB8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x0000026ECD657EB8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x0000026ECD657EB8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x0000026ECC595198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x0000026ECC595198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x0000026ECC595198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x0000026ECC595198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "h2 (?, 1, 251, 100)\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x0000026ECC595198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x0000026ECC595198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x0000026ECC595198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x0000026ECC595198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-3-3f45c8775166>:14: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000026ECDA799B0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000026ECDA799B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000026ECDA799B0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000026ECDA799B0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "flatten Tensor(\"flatten/Reshape:0\", shape=(?, 25100), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-3-3f45c8775166>:17: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000026ECDA799B0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000026ECDA799B0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000026ECDA799B0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000026ECDA799B0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "dense1 Tensor(\"dense/Relu:0\", shape=(?, 1024), dtype=float32)\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000026ECDA799B0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000026ECDA799B0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000026ECDA799B0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000026ECDA799B0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "y (?, 513)\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 20, 513, 1])\n",
    "print(\"x\",x.shape)\n",
    "\n",
    "h1 = tf.layers.conv2d(x, filters = 50, kernel_size=(18,2), strides=(1,1), activation=\"relu\", padding = \"valid\")\n",
    "print(\"h1\",h1.shape)\n",
    "\n",
    "h1_drop = tf.layers.dropout(h1, rate = 0.1)\n",
    "\n",
    "h2 = tf.layers.conv2d(h1_drop, filters = 100, kernel_size=(3,12), strides=(2,2), activation=\"relu\", padding = \"valid\")\n",
    "print(\"h2\",h2.shape)\n",
    "\n",
    "h2_drop = tf.layers.dropout(h2, rate = 0.2)\n",
    "\n",
    "flatten_layer = tf.layers.flatten(h2_drop)\n",
    "print(\"flatten\", flatten_layer)\n",
    "\n",
    "dense_1 = tf.layers.dense(flatten_layer, 1024, activation = \"relu\")\n",
    "print(\"dense1\" ,dense_1)\n",
    "\n",
    "y = tf.layers.dense(dense_1,513,activation=\"relu\")\n",
    "print(\"y\",y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataset for 2D CNN:\n",
    "\n",
    "Here, we append 20 silent frames uniformly in the range of 0 to the minimum value in that data.\n",
    "Then we create a 3D data where each frame consists of 20 previous frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (19, 513)\n",
      "(2478, 513)\n",
      "(2459, 20, 513)\n"
     ]
    }
   ],
   "source": [
    "X_silent_frames = np.random.uniform(low=0.0,high=np.amin(X_abs),size=(19,513))\n",
    "print(type(X_silent_frames),X_silent_frames.shape)\n",
    "\n",
    "X_concat = np.concatenate((X_silent_frames, X_abs), axis = 0)\n",
    "print(X_concat.shape)\n",
    "\n",
    "X_aug = np.empty([X_abs.shape[0],20,513])\n",
    "\n",
    "for i in range(19,X_abs.shape[0]):\n",
    "    X_aug[i-19] = X_concat[i-19:i+1,:]\n",
    "    \n",
    "print(X_aug.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into 250 batches each of shape (10,20,513)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 20, 513) (10, 513)\n"
     ]
    }
   ],
   "source": [
    "batch_S=np.array_split(S_abs,250)\n",
    "batch_X=np.array_split(X_aug,250)\n",
    "batches=len(batch_X)\n",
    "print(batch_X[0].shape,batch_S[0].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean squared error is used to calculate the loss on training. Adam Optimizer is used with a learning rate of 0.0001 and run for 100 epochs ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sanky\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "y_ = tf.placeholder(tf.float32, [None,513])\n",
    "error = tf.losses.mean_squared_error(y_,y)\n",
    "optimizer = tf.train.AdamOptimizer(0.0001).minimize(error)\n",
    "loss_log = []\n",
    "init = tf.global_variables_initializer()\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtained a loss of approx. 0.001 in 100 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "loss: 0.07505544050686876\n",
      "Epoch: 1\n",
      "loss: 0.04785396481314092\n",
      "Epoch: 2\n",
      "loss: 0.024933920323397616\n",
      "Epoch: 3\n",
      "loss: 0.01585378907667473\n",
      "Epoch: 4\n",
      "loss: 0.012036051739414688\n",
      "Epoch: 5\n",
      "loss: 0.009984532903297804\n",
      "Epoch: 6\n",
      "loss: 0.008981215081439587\n",
      "Epoch: 7\n",
      "loss: 0.008600238814615295\n",
      "Epoch: 8\n",
      "loss: 0.007878675508953166\n",
      "Epoch: 9\n",
      "loss: 0.0077252776430395895\n",
      "Epoch: 10\n",
      "loss: 0.00901262122442131\n",
      "Epoch: 11\n",
      "loss: 0.008280378688839846\n",
      "Epoch: 12\n",
      "loss: 0.006341080901242094\n",
      "Epoch: 13\n",
      "loss: 0.005297363792458782\n",
      "Epoch: 14\n",
      "loss: 0.0048154142039566064\n",
      "Epoch: 15\n",
      "loss: 0.0045634268961439375\n",
      "Epoch: 16\n",
      "loss: 0.004378801583057793\n",
      "Epoch: 17\n",
      "loss: 0.004382945528166602\n",
      "Epoch: 18\n",
      "loss: 0.004487465191894443\n",
      "Epoch: 19\n",
      "loss: 0.0043948167345370165\n",
      "Epoch: 20\n",
      "loss: 0.004346266303356969\n",
      "Epoch: 21\n",
      "loss: 0.0045718168844323375\n",
      "Epoch: 22\n",
      "loss: 0.004404086481677951\n",
      "Epoch: 23\n",
      "loss: 0.004310132772588986\n",
      "Epoch: 24\n",
      "loss: 0.004010167736843868\n",
      "Epoch: 25\n",
      "loss: 0.003683302089335484\n",
      "Epoch: 26\n",
      "loss: 0.004464467364428856\n",
      "Epoch: 27\n",
      "loss: 0.0038377678760880374\n",
      "Epoch: 28\n",
      "loss: 0.003157048416964244\n",
      "Epoch: 29\n",
      "loss: 0.0031536020778730744\n",
      "Epoch: 30\n",
      "loss: 0.00317444238148164\n",
      "Epoch: 31\n",
      "loss: 0.002941919042787049\n",
      "Epoch: 32\n",
      "loss: 0.00273849995501223\n",
      "Epoch: 33\n",
      "loss: 0.002681479210034013\n",
      "Epoch: 34\n",
      "loss: 0.002776948475810059\n",
      "Epoch: 35\n",
      "loss: 0.0030852857475147173\n",
      "Epoch: 36\n",
      "loss: 0.0029831606805237245\n",
      "Epoch: 37\n",
      "loss: 0.003177366150150192\n",
      "Epoch: 38\n",
      "loss: 0.003110751513086143\n",
      "Epoch: 39\n",
      "loss: 0.0037759364514859044\n",
      "Epoch: 40\n",
      "loss: 0.0036972593091923046\n",
      "Epoch: 41\n",
      "loss: 0.00340116435517848\n",
      "Epoch: 42\n",
      "loss: 0.00271237401086546\n",
      "Epoch: 43\n",
      "loss: 0.0024879709918968727\n",
      "Epoch: 44\n",
      "loss: 0.0024599696153527477\n",
      "Epoch: 45\n",
      "loss: 0.002361811783932353\n",
      "Epoch: 46\n",
      "loss: 0.00222934909875039\n",
      "Epoch: 47\n",
      "loss: 0.0022460421434916497\n",
      "Epoch: 48\n",
      "loss: 0.0024361470605836076\n",
      "Epoch: 49\n",
      "loss: 0.002608639751048031\n",
      "Epoch: 50\n",
      "loss: 0.0024104848949500594\n",
      "Epoch: 51\n",
      "loss: 0.0024646483705764695\n",
      "Epoch: 52\n",
      "loss: 0.0022560041255492254\n",
      "Epoch: 53\n",
      "loss: 0.0022662949139776174\n",
      "Epoch: 54\n",
      "loss: 0.002357705368871393\n",
      "Epoch: 55\n",
      "loss: 0.0024144963647122495\n",
      "Epoch: 56\n",
      "loss: 0.0027576916266298214\n",
      "Epoch: 57\n",
      "loss: 0.0032361978520712\n",
      "Epoch: 58\n",
      "loss: 0.00306962880390347\n",
      "Epoch: 59\n",
      "loss: 0.0025551617332166643\n",
      "Epoch: 60\n",
      "loss: 0.002300796015357264\n",
      "Epoch: 61\n",
      "loss: 0.0023846758884974407\n",
      "Epoch: 62\n",
      "loss: 0.0021594944270473208\n",
      "Epoch: 63\n",
      "loss: 0.0030307141583289193\n",
      "Epoch: 64\n",
      "loss: 0.0030948126518633217\n",
      "Epoch: 65\n",
      "loss: 0.002484213249575987\n",
      "Epoch: 66\n",
      "loss: 0.001870441166265664\n",
      "Epoch: 67\n",
      "loss: 0.0016095005686402146\n",
      "Epoch: 68\n",
      "loss: 0.0015420489820280635\n",
      "Epoch: 69\n",
      "loss: 0.0015981024987668207\n",
      "Epoch: 70\n",
      "loss: 0.0016368685797715442\n",
      "Epoch: 71\n",
      "loss: 0.0017224983608539334\n",
      "Epoch: 72\n",
      "loss: 0.001821569461688341\n",
      "Epoch: 73\n",
      "loss: 0.0018305544426038978\n",
      "Epoch: 74\n",
      "loss: 0.0017509370838124595\n",
      "Epoch: 75\n",
      "loss: 0.0018662660142017558\n",
      "Epoch: 76\n",
      "loss: 0.0018773658698191867\n",
      "Epoch: 77\n",
      "loss: 0.0019478872905565367\n",
      "Epoch: 78\n",
      "loss: 0.0019344642746473256\n",
      "Epoch: 79\n",
      "loss: 0.003077902651792101\n",
      "Epoch: 80\n",
      "loss: 0.002408630343074037\n",
      "Epoch: 81\n",
      "loss: 0.0021795542735417255\n",
      "Epoch: 82\n",
      "loss: 0.0018884266693530662\n",
      "Epoch: 83\n",
      "loss: 0.001689757667347294\n",
      "Epoch: 84\n",
      "loss: 0.0017230059725916362\n",
      "Epoch: 85\n",
      "loss: 0.0017174596912227572\n",
      "Epoch: 86\n",
      "loss: 0.0020348711844380887\n",
      "Epoch: 87\n",
      "loss: 0.002142291392206971\n",
      "Epoch: 88\n",
      "loss: 0.0021317101475760865\n",
      "Epoch: 89\n",
      "loss: 0.0018812362695134653\n",
      "Epoch: 90\n",
      "loss: 0.001702805255572457\n",
      "Epoch: 91\n",
      "loss: 0.0015772705181589118\n",
      "Epoch: 92\n",
      "loss: 0.0014904577405395684\n",
      "Epoch: 93\n",
      "loss: 0.0014633674366596097\n",
      "Epoch: 94\n",
      "loss: 0.001433783302491065\n",
      "Epoch: 95\n",
      "loss: 0.0014183757842129126\n",
      "Epoch: 96\n",
      "loss: 0.0014757696950364334\n",
      "Epoch: 97\n",
      "loss: 0.0016555003646917612\n",
      "Epoch: 98\n",
      "loss: 0.0018384672379906989\n",
      "Epoch: 99\n",
      "loss: 0.0018333457798216841\n"
     ]
    }
   ],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "\n",
    "\n",
    "sess2dcnn = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "sess2dcnn.run(init)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch:\", epoch)\n",
    "    temp_loss=0\n",
    "    for _ in range(batches):\n",
    "        batch_xs, batch_ys = batch_X[_], batch_S[_]\n",
    "        batch_xs=np.expand_dims(batch_xs, axis=3).astype('float32')\n",
    "        _, loss= sess2dcnn.run([optimizer, error], feed_dict={x:batch_xs,y_:batch_ys})\n",
    "        \n",
    "        temp_loss+=loss\n",
    "    loss_log.append(temp_loss/batches)\n",
    "    print(\"loss:\",temp_loss/batches)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the network on test1 audio. Test files that are fed into the network are created in a similar manner as the dirty train input i.e. appending 20 previous frames to each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142, 513)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1, sr=librosa.load(\"data/test_x_01.wav\", sr=None)\n",
    "test1_stft=librosa.stft(test1, n_fft=1024, hop_length=512)\n",
    "test1_abs=np.abs(np.transpose(test1_stft))\n",
    "test1_silent_frames = np.random.uniform(low=0.0, high=np.amin(test1_abs),size=(19,513))\n",
    "test1_concat = np.concatenate((test1_silent_frames, test1_abs), axis = 0)\n",
    "\n",
    "test1_aug = np.empty([test1_abs.shape[0],20,513])\n",
    "\n",
    "for i in range(19,test1_abs.shape[0]):\n",
    "    test1_aug[i-19] = test1_concat[i-19:i+1,:]\n",
    "\n",
    "test1_aug=np.expand_dims(test1_aug,axis=3)\n",
    "test1_output= sess2dcnn.run(y, feed_dict={x:test1_aug})\n",
    "test1_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(513, 142)\n",
      "(72619,)\n"
     ]
    }
   ],
   "source": [
    "clean_test1_2d=(test1_stft/np.abs(test1_stft))*(np.transpose(test1_output))\n",
    "print(clean_test1_2d.shape)\n",
    "clean_test1_istft_2d=librosa.istft(clean_test1_2d, hop_length=512, length=test1.shape[0])\n",
    "print(clean_test1_istft_2d.shape)\n",
    "librosa.output.write_wav(\"test_s_01_recons_2dcnn.wav\", clean_test1_istft_2d, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the network on test 2 audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(380, 513)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2, sr=librosa.load(\"data/test_x_02.wav\", sr=None)\n",
    "test2_stft=librosa.stft(test2, n_fft=1024, hop_length=512)\n",
    "test2_abs=np.abs(np.transpose(test2_stft))\n",
    "test2_silent_frames = np.random.uniform(low=0.0, high=np.amin(test2_abs),size=(19,513))\n",
    "test2_concat = np.concatenate((test2_silent_frames, test2_abs), axis = 0)\n",
    "\n",
    "test2_aug = np.empty([test2_abs.shape[0],20,513])\n",
    "\n",
    "for i in range(19,test2_abs.shape[0]):\n",
    "    test2_aug[i-19] = test2_concat[i-19:i+1,:]\n",
    "\n",
    "test2_aug=np.expand_dims(test2_aug,axis=3)\n",
    "test2_output= sess2dcnn.run(y, feed_dict={x:test2_aug})\n",
    "test2_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(513, 380)\n",
      "(194353,)\n"
     ]
    }
   ],
   "source": [
    "clean_test2_2d=(test2_stft/np.abs(test2_stft))*(np.transpose(test2_output))\n",
    "print(clean_test2_2d.shape)\n",
    "clean_test2_istft_2d=librosa.istft(clean_test2_2d, hop_length=512, length=test2.shape[0])\n",
    "print(clean_test2_istft_2d.shape)\n",
    "librosa.output.write_wav(\"test_s_02_recons_2dcnn.wav\", clean_test2_istft_2d, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate SNR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2459, 513)\n"
     ]
    }
   ],
   "source": [
    "train_dirty_output= sess2dcnn.run(y, feed_dict={x:np.expand_dims(X_aug, axis=3)})\n",
    "print(train_dirty_output.shape)\n",
    "clean_train1=(X/np.abs(X))*(np.transpose(train_dirty_output))\n",
    "clean_train1.shape\n",
    "clean_train1_istft_2d=librosa.istft(clean_train1, hop_length=512, length=sn.shape[0])\n",
    "clean_train1_istft_2d.shape\n",
    "librosa.output.write_wav(\"train_dirty_recons_2dcnn.wav\", clean_train1_istft_2d, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR on train dirty output: 7.308210730552673\n"
     ]
    }
   ],
   "source": [
    "num = (np.sum(sn*sn))\n",
    "den = np.sum(np.square(sn-clean_train1_istft_2d))\n",
    "SNR =10*np.log10(num/den)\n",
    "print(\"SNR on train dirty output:\",SNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR on test 1 output: 7.778724431991577\n"
     ]
    }
   ],
   "source": [
    "num = (np.sum(test1*test1))\n",
    "den = np.sum(np.square(test1-clean_test1_istft_2d))\n",
    "SNR =10*np.log10(num/den)\n",
    "print(\"SNR on test 1 output:\",SNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR on test 2 output: 6.713163256645203\n"
     ]
    }
   ],
   "source": [
    "num = (np.sum(test2*test2))\n",
    "den = np.sum(np.square(test2-clean_test2_istft_2d))\n",
    "SNR =10*np.log10(num/den)\n",
    "print(\"SNR on test 2 output:\",SNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess2dcnn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
