{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Denoising using 1D CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dirty and clean audio files to be used for training purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2459, 513)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s, sr=librosa.load(\"data/train_clean_male.wav\", sr=None)\n",
    "S=librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "sn, sr=librosa.load(\"data/train_dirty_male.wav\", sr=None)\n",
    "X=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "S_abs=np.abs(np.transpose(S))\n",
    "X_abs=np.abs(np.transpose(X))\n",
    "X_abs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model architecture:\n",
    "\n",
    "> 1st Conv1D layer has kernel size of 3, strides is 1 and 25 filters with relu activation and no padding.\n",
    "\n",
    "> 2nd Conv1D layer has kernel size of 5, strides is 2 and 50 filters with relu activation and no padding.\n",
    "    \n",
    "> 3rd Conv1D layer has kernel size of 5, strides is 2 and 75 filters with relu activation and no padding.\n",
    "    \n",
    "> The output of the 3rd Conv1D is flattened and fed into a dense layer with 1026 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (?, 513, 1)\n",
      "WARNING:tensorflow:From <ipython-input-3-0d94db3c7a67>:3: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv1D` instead.\n",
      "WARNING:tensorflow:Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x0000029DAD57FCF8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x0000029DAD57FCF8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x0000029DAD57FCF8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x0000029DAD57FCF8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "h1 (?, 511, 25)\n",
      "WARNING:tensorflow:Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x0000029DAD57FCF8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x0000029DAD57FCF8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x0000029DAD57FCF8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x0000029DAD57FCF8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "h2 (?, 254, 50)\n",
      "WARNING:tensorflow:Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x0000029DAD57FCF8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x0000029DAD57FCF8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x0000029DAD57FCF8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x0000029DAD57FCF8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "h3 (?, 125, 75)\n",
      "WARNING:tensorflow:From <ipython-input-3-0d94db3c7a67>:9: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x0000029DAD57FCF8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x0000029DAD57FCF8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x0000029DAD57FCF8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x0000029DAD57FCF8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-3-0d94db3c7a67>:10: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000029DADC01CF8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000029DADC01CF8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000029DADC01CF8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000029DADC01CF8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "h4 (?, 9375)\n",
      "WARNING:tensorflow:From <ipython-input-3-0d94db3c7a67>:12: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000029DADC01CF8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000029DADC01CF8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000029DADC01CF8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000029DADC01CF8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000029DADC01160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000029DADC01160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000029DADC01160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000029DADC01160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "y (?, 513)\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 513, 1])\n",
    "print(\"x\",x.shape)\n",
    "h1 = tf.layers.conv1d(x, filters = 25, kernel_size=3, strides=1, activation=\"relu\", kernel_initializer=\"he_normal\", padding = \"valid\")\n",
    "print(\"h1\",h1.shape)\n",
    "h2 = tf.layers.conv1d(h1, filters = 50,kernel_size=5, strides=2, activation=\"relu\", kernel_initializer=\"he_normal\",padding = \"valid\")\n",
    "print(\"h2\",h2.shape)\n",
    "h3 = tf.layers.conv1d(h2, filters = 75,kernel_size=5, strides=2, activation=\"relu\", kernel_initializer=\"he_normal\",padding = \"valid\")\n",
    "print(\"h3\",h3.shape)\n",
    "h3_drop = tf.layers.dropout(h3, rate = 0.3)\n",
    "h4 = tf.layers.flatten(h3_drop)\n",
    "print(\"h4\",h4.shape)\n",
    "h5 = tf.layers.dense(h4,1026, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
    "y = tf.layers.dense(h5,513,activation=\"relu\", kernel_initializer=\"he_normal\")\n",
    "print(\"y\",y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean squared error is used to calculate the loss on training. Adam Optimizer is used with a learning rate of 0.0001 and run for 200 epochs .       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sanky\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "y_ = tf.placeholder(tf.float32, [None,513])\n",
    "error = tf.losses.mean_squared_error(y_,y)\n",
    "optimizer = tf.train.AdamOptimizer(0.0001).minimize(error)\n",
    "loss_log = []\n",
    "init = tf.global_variables_initializer()\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is split into 250 batches each of ~(10,513)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2459, 513) 250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 513)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_S=np.array_split(S_abs,250)\n",
    "batch_X=np.array_split(X_abs,250)\n",
    "batches=len(batch_X)\n",
    "print(S_abs.shape,len(batch_X))\n",
    "batch_S[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtained a loss of approx. 0.0007 in 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "loss 0.0446876526447013\n",
      "Epoch:  1\n",
      "loss 0.020439540092425885\n",
      "Epoch:  2\n",
      "loss 0.01625603042115108\n",
      "Epoch:  3\n",
      "loss 0.014094875444396165\n",
      "Epoch:  4\n",
      "loss 0.012320511776633793\n",
      "Epoch:  5\n",
      "loss 0.01120607516838936\n",
      "Epoch:  6\n",
      "loss 0.010150949994160328\n",
      "Epoch:  7\n",
      "loss 0.009225268380730995\n",
      "Epoch:  8\n",
      "loss 0.008618526328442386\n",
      "Epoch:  9\n",
      "loss 0.00814693107252242\n",
      "Epoch:  10\n",
      "loss 0.007793657429647283\n",
      "Epoch:  11\n",
      "loss 0.00750395778096572\n",
      "Epoch:  12\n",
      "loss 0.007210249029667466\n",
      "Epoch:  13\n",
      "loss 0.006612117763841525\n",
      "Epoch:  14\n",
      "loss 0.006155847539979732\n",
      "Epoch:  15\n",
      "loss 0.0059222700202371924\n",
      "Epoch:  16\n",
      "loss 0.00582705008207995\n",
      "Epoch:  17\n",
      "loss 0.005708669135026867\n",
      "Epoch:  18\n",
      "loss 0.005814338088835939\n",
      "Epoch:  19\n",
      "loss 0.005770865869548288\n",
      "Epoch:  20\n",
      "loss 0.005779512162989704\n",
      "Epoch:  21\n",
      "loss 0.005456983837546432\n",
      "Epoch:  22\n",
      "loss 0.005126315555120527\n",
      "Epoch:  23\n",
      "loss 0.004869292139730533\n",
      "Epoch:  24\n",
      "loss 0.004609501395643747\n",
      "Epoch:  25\n",
      "loss 0.004613217738078674\n",
      "Epoch:  26\n",
      "loss 0.004702711955171253\n",
      "Epoch:  27\n",
      "loss 0.004613384020980447\n",
      "Epoch:  28\n",
      "loss 0.004639270177613071\n",
      "Epoch:  29\n",
      "loss 0.00456166319111071\n",
      "Epoch:  30\n",
      "loss 0.0045049507649600855\n",
      "Epoch:  31\n",
      "loss 0.0042141518424032255\n",
      "Epoch:  32\n",
      "loss 0.004073929583777499\n",
      "Epoch:  33\n",
      "loss 0.004018387983378489\n",
      "Epoch:  34\n",
      "loss 0.0039196598699491\n",
      "Epoch:  35\n",
      "loss 0.003948401940186159\n",
      "Epoch:  36\n",
      "loss 0.0036869756834203146\n",
      "Epoch:  37\n",
      "loss 0.0033731632950803033\n",
      "Epoch:  38\n",
      "loss 0.0030843491697596617\n",
      "Epoch:  39\n",
      "loss 0.0028544412331830246\n",
      "Epoch:  40\n",
      "loss 0.0026400127342931226\n",
      "Epoch:  41\n",
      "loss 0.002498481887843809\n",
      "Epoch:  42\n",
      "loss 0.0025264155668846796\n",
      "Epoch:  43\n",
      "loss 0.0026938845101249173\n",
      "Epoch:  44\n",
      "loss 0.0029081902593388804\n",
      "Epoch:  45\n",
      "loss 0.003124468429668923\n",
      "Epoch:  46\n",
      "loss 0.003040124858074705\n",
      "Epoch:  47\n",
      "loss 0.0027564359476309618\n",
      "Epoch:  48\n",
      "loss 0.0024468293649915723\n",
      "Epoch:  49\n",
      "loss 0.0021556004616577413\n",
      "Epoch:  50\n",
      "loss 0.0020867318155869726\n",
      "Epoch:  51\n",
      "loss 0.0021002240595043987\n",
      "Epoch:  52\n",
      "loss 0.0020429703032350515\n",
      "Epoch:  53\n",
      "loss 0.0020171035510393267\n",
      "Epoch:  54\n",
      "loss 0.0020974822142670745\n",
      "Epoch:  55\n",
      "loss 0.0022665432335415973\n",
      "Epoch:  56\n",
      "loss 0.002471202987369907\n",
      "Epoch:  57\n",
      "loss 0.0026616114886273863\n",
      "Epoch:  58\n",
      "loss 0.002638671353335667\n",
      "Epoch:  59\n",
      "loss 0.00230690013608546\n",
      "Epoch:  60\n",
      "loss 0.0019318392839777516\n",
      "Epoch:  61\n",
      "loss 0.001766711097840016\n",
      "Epoch:  62\n",
      "loss 0.0017113995379550034\n",
      "Epoch:  63\n",
      "loss 0.001753833542989014\n",
      "Epoch:  64\n",
      "loss 0.0018321271488603089\n",
      "Epoch:  65\n",
      "loss 0.0019230227589432617\n",
      "Epoch:  66\n",
      "loss 0.0019544890866454805\n",
      "Epoch:  67\n",
      "loss 0.0020577100136724767\n",
      "Epoch:  68\n",
      "loss 0.002084244371733803\n",
      "Epoch:  69\n",
      "loss 0.0018801390583757893\n",
      "Epoch:  70\n",
      "loss 0.00192909657934797\n",
      "Epoch:  71\n",
      "loss 0.0019520455971942282\n",
      "Epoch:  72\n",
      "loss 0.0019757402995601294\n",
      "Epoch:  73\n",
      "loss 0.0017706934176712822\n",
      "Epoch:  74\n",
      "loss 0.001641852531767654\n",
      "Epoch:  75\n",
      "loss 0.001598652875454718\n",
      "Epoch:  76\n",
      "loss 0.0016794373661032295\n",
      "Epoch:  77\n",
      "loss 0.0017250672556328936\n",
      "Epoch:  78\n",
      "loss 0.0016177657005137008\n",
      "Epoch:  79\n",
      "loss 0.0015250265989088802\n",
      "Epoch:  80\n",
      "loss 0.001420870442112573\n",
      "Epoch:  81\n",
      "loss 0.0015172448151861318\n",
      "Epoch:  82\n",
      "loss 0.001418027405776229\n",
      "Epoch:  83\n",
      "loss 0.0012606056552303927\n",
      "Epoch:  84\n",
      "loss 0.001248873719436233\n",
      "Epoch:  85\n",
      "loss 0.0013228171417777048\n",
      "Epoch:  86\n",
      "loss 0.001333224500878714\n",
      "Epoch:  87\n",
      "loss 0.00133791276847478\n",
      "Epoch:  88\n",
      "loss 0.0013012786978360963\n",
      "Epoch:  89\n",
      "loss 0.0011937624893216708\n",
      "Epoch:  90\n",
      "loss 0.0011765597399280522\n",
      "Epoch:  91\n",
      "loss 0.001184773071192467\n",
      "Epoch:  92\n",
      "loss 0.0012165517730463762\n",
      "Epoch:  93\n",
      "loss 0.0014900467005718383\n",
      "Epoch:  94\n",
      "loss 0.001650637819115218\n",
      "Epoch:  95\n",
      "loss 0.0014288678191769577\n",
      "Epoch:  96\n",
      "loss 0.001235215054564833\n",
      "Epoch:  97\n",
      "loss 0.0010715559532036422\n",
      "Epoch:  98\n",
      "loss 0.0010195398359137472\n",
      "Epoch:  99\n",
      "loss 0.000980528607404267\n",
      "Epoch:  100\n",
      "loss 0.0010089901204482885\n",
      "Epoch:  101\n",
      "loss 0.0010437371822972637\n",
      "Epoch:  102\n",
      "loss 0.0011878503824409564\n",
      "Epoch:  103\n",
      "loss 0.0012058464883211854\n",
      "Epoch:  104\n",
      "loss 0.0011756356337828038\n",
      "Epoch:  105\n",
      "loss 0.0014202804279739212\n",
      "Epoch:  106\n",
      "loss 0.0014789684052593658\n",
      "Epoch:  107\n",
      "loss 0.0012879059714032337\n",
      "Epoch:  108\n",
      "loss 0.0010821433795463237\n",
      "Epoch:  109\n",
      "loss 0.0009800377948213281\n",
      "Epoch:  110\n",
      "loss 0.0009358048458634584\n",
      "Epoch:  111\n",
      "loss 0.0009249911067217908\n",
      "Epoch:  112\n",
      "loss 0.0009385510459233046\n",
      "Epoch:  113\n",
      "loss 0.0009694429204155313\n",
      "Epoch:  114\n",
      "loss 0.0010016600506496615\n",
      "Epoch:  115\n",
      "loss 0.0010955650029427489\n",
      "Epoch:  116\n",
      "loss 0.0011101639054159024\n",
      "Epoch:  117\n",
      "loss 0.0010924602288869209\n",
      "Epoch:  118\n",
      "loss 0.0010834315681131556\n",
      "Epoch:  119\n",
      "loss 0.0010895559486853016\n",
      "Epoch:  120\n",
      "loss 0.0010952778764876713\n",
      "Epoch:  121\n",
      "loss 0.0014638852254829544\n",
      "Epoch:  122\n",
      "loss 0.0013183835699201155\n",
      "Epoch:  123\n",
      "loss 0.001311552143744848\n",
      "Epoch:  124\n",
      "loss 0.0011982574563753588\n",
      "Epoch:  125\n",
      "loss 0.0011083619892560818\n",
      "Epoch:  126\n",
      "loss 0.0010423062931240565\n",
      "Epoch:  127\n",
      "loss 0.0010288277987119728\n",
      "Epoch:  128\n",
      "loss 0.0009265472412189411\n",
      "Epoch:  129\n",
      "loss 0.0008823839640263032\n",
      "Epoch:  130\n",
      "loss 0.0009002223234529083\n",
      "Epoch:  131\n",
      "loss 0.0009478185661610042\n",
      "Epoch:  132\n",
      "loss 0.0010203072618078296\n",
      "Epoch:  133\n",
      "loss 0.0011809862971058464\n",
      "Epoch:  134\n",
      "loss 0.0010940819657134853\n",
      "Epoch:  135\n",
      "loss 0.0011043341984641301\n",
      "Epoch:  136\n",
      "loss 0.0011376177483980428\n",
      "Epoch:  137\n",
      "loss 0.0011410977872255898\n",
      "Epoch:  138\n",
      "loss 0.0010317251879205288\n",
      "Epoch:  139\n",
      "loss 0.0009758546139837563\n",
      "Epoch:  140\n",
      "loss 0.0009654719707577897\n",
      "Epoch:  141\n",
      "loss 0.0009226702246451169\n",
      "Epoch:  142\n",
      "loss 0.0009366405021755781\n",
      "Epoch:  143\n",
      "loss 0.0009220746190458157\n",
      "Epoch:  144\n",
      "loss 0.0008857425913029146\n",
      "Epoch:  145\n",
      "loss 0.00099527402863896\n",
      "Epoch:  146\n",
      "loss 0.0010683736964892886\n",
      "Epoch:  147\n",
      "loss 0.000990837182793257\n",
      "Epoch:  148\n",
      "loss 0.0009471251388476958\n",
      "Epoch:  149\n",
      "loss 0.0009187941840318672\n",
      "Epoch:  150\n",
      "loss 0.0008995470466852567\n",
      "Epoch:  151\n",
      "loss 0.000971070226001757\n",
      "Epoch:  152\n",
      "loss 0.0009172909001590597\n",
      "Epoch:  153\n",
      "loss 0.0009695553076453507\n",
      "Epoch:  154\n",
      "loss 0.0009691774342663848\n",
      "Epoch:  155\n",
      "loss 0.0009781037706961798\n",
      "Epoch:  156\n",
      "loss 0.0010322004658100924\n",
      "Epoch:  157\n",
      "loss 0.0012962758331523218\n",
      "Epoch:  158\n",
      "loss 0.0015547782458343136\n",
      "Epoch:  159\n",
      "loss 0.0011001685045703199\n",
      "Epoch:  160\n",
      "loss 0.000977881564418567\n",
      "Epoch:  161\n",
      "loss 0.0009204086660229223\n",
      "Epoch:  162\n",
      "loss 0.0008268285669746547\n",
      "Epoch:  163\n",
      "loss 0.0007490266654913285\n",
      "Epoch:  164\n",
      "loss 0.0007597128754769074\n",
      "Epoch:  165\n",
      "loss 0.000820620873992084\n",
      "Epoch:  166\n",
      "loss 0.0008679331025232386\n",
      "Epoch:  167\n",
      "loss 0.0008702451701628888\n",
      "Epoch:  168\n",
      "loss 0.0008773645502878935\n",
      "Epoch:  169\n",
      "loss 0.0008769002525541509\n",
      "Epoch:  170\n",
      "loss 0.00094120063182163\n",
      "Epoch:  171\n",
      "loss 0.000936513798436863\n",
      "Epoch:  172\n",
      "loss 0.0008351714553355122\n",
      "Epoch:  173\n",
      "loss 0.0008127480232014932\n",
      "Epoch:  174\n",
      "loss 0.0007886745631822123\n",
      "Epoch:  175\n",
      "loss 0.0007768321839266718\n",
      "Epoch:  176\n",
      "loss 0.0008081465008781378\n",
      "Epoch:  177\n",
      "loss 0.0008221232305641024\n",
      "Epoch:  178\n",
      "loss 0.0008611053391432506\n",
      "Epoch:  179\n",
      "loss 0.000844688140829021\n",
      "Epoch:  180\n",
      "loss 0.0008701248092384048\n",
      "Epoch:  181\n",
      "loss 0.000984487840143629\n",
      "Epoch:  182\n",
      "loss 0.0011143078201976096\n",
      "Epoch:  183\n",
      "loss 0.001101241344022128\n",
      "Epoch:  184\n",
      "loss 0.0008939039147371659\n",
      "Epoch:  185\n",
      "loss 0.0007910965790597402\n",
      "Epoch:  186\n",
      "loss 0.0007575136396608287\n",
      "Epoch:  187\n",
      "loss 0.0007483548086074734\n",
      "Epoch:  188\n",
      "loss 0.0007243746010735777\n",
      "Epoch:  189\n",
      "loss 0.0007279357664538111\n",
      "Epoch:  190\n",
      "loss 0.0008045747515534458\n",
      "Epoch:  191\n",
      "loss 0.0009352031864091259\n",
      "Epoch:  192\n",
      "loss 0.0010182858475573085\n",
      "Epoch:  193\n",
      "loss 0.0010851859116319247\n",
      "Epoch:  194\n",
      "loss 0.0009642148300354165\n",
      "Epoch:  195\n",
      "loss 0.0008481025528490136\n",
      "Epoch:  196\n",
      "loss 0.0007667483139939577\n",
      "Epoch:  197\n",
      "loss 0.0007186559588935779\n",
      "Epoch:  198\n",
      "loss 0.0007396710498815082\n",
      "Epoch:  199\n",
      "loss 0.0007766344547653716\n"
     ]
    }
   ],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "\n",
    "sess1 = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "#sess1 = tf.Session()\n",
    "sess1.run(init)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch: \", epoch)\n",
    "    temp_loss=0\n",
    "    for _ in range(batches):\n",
    "        batch_xs, batch_ys = batch_X[_], batch_S[_]\n",
    "        batch_xs=np.expand_dims(batch_xs, axis=2).astype('float32')\n",
    "#         batch_ys=np.expand_dims(batch_ys, axis=2)\n",
    "        #print(batch_xs.shape,batch_ys.shape)\n",
    "\n",
    "        _, loss,k = sess1.run([optimizer, error,y], feed_dict={x:batch_xs,y_:batch_ys})\n",
    "        \n",
    "        temp_loss+=loss\n",
    "    loss_log.append(temp_loss/batches)\n",
    "    print(\"loss\",temp_loss/batches)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the network on test1 audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142, 513)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1, sr=librosa.load(\"data/test_x_01.wav\", sr=None)\n",
    "test1_stft=librosa.stft(test1, n_fft=1024, hop_length=512)\n",
    "test1_abs=np.abs(np.transpose(test1_stft))\n",
    "test1_abs=np.expand_dims(test1_abs,axis=2)\n",
    "test1_output= sess1.run(y, feed_dict={x:test1_abs})\n",
    "test1_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test1=(test1_stft/np.abs(test1_stft))*(np.transpose(test1_output))\n",
    "clean_test1.shape\n",
    "clean_test1_istft_1d=librosa.istft(clean_test1, hop_length=512, length=test1.shape[0])\n",
    "clean_test1_istft_1d.shape\n",
    "librosa.output.write_wav(\"test_s_01_recons_1dcnn.wav\", clean_test1_istft_1d, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the network on test 2 audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(380, 513)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2, sr=librosa.load(\"data/test_x_02.wav\", sr=None)\n",
    "test2_stft=librosa.stft(test2, n_fft=1024, hop_length=512)\n",
    "test2_abs=np.abs(np.transpose(test2_stft))\n",
    "test2_abs=np.expand_dims(test2_abs,axis=2)\n",
    "test2_output= sess1.run(y, feed_dict={x:test2_abs})\n",
    "test2_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test2=(test2_stft/np.abs(test2_stft))*(np.transpose(test2_output))\n",
    "clean_test2.shape\n",
    "clean_test2_istft_1d=librosa.istft(clean_test2, hop_length=512,length=test2.shape[0])\n",
    "clean_test2_istft_1d.shape\n",
    "librosa.output.write_wav(\"test_s_02_recons_1dcnn.wav\", clean_test2_istft_1d, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate SNR on cleaned dirty train audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2459, 513)\n"
     ]
    }
   ],
   "source": [
    "train_dirty_output= sess1.run(y, feed_dict={x:np.expand_dims(X_abs, axis=2)})\n",
    "print(train_dirty_output.shape)\n",
    "clean_train1=(X/np.abs(X))*(np.transpose(train_dirty_output))\n",
    "clean_train1.shape\n",
    "clean_train1_istft_1d=librosa.istft(clean_train1, hop_length=512, length=sn.shape[0])\n",
    "clean_train1_istft_1d.shape\n",
    "librosa.output.write_wav(\"train_dirty_recons_1dcnn.wav\", clean_train1_istft_1d, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR on train dirty audio: 7.484267950057983\n"
     ]
    }
   ],
   "source": [
    "num = (np.sum(sn*sn))\n",
    "den = np.sum(np.square(sn-clean_train1_istft_1d))\n",
    "SNR =10*np.log10(num/den)\n",
    "print(\"SNR on train dirty audio:\",SNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR on test 1 output: 8.106775283813477\n"
     ]
    }
   ],
   "source": [
    "num = (np.sum(test1*test1))\n",
    "den = np.sum(np.square(test1-clean_test1_istft_1d))\n",
    "SNR =10*np.log10(num/den)\n",
    "print(\"SNR on test 1 output:\",SNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR on test 2 output: 7.973528504371643\n"
     ]
    }
   ],
   "source": [
    "num = (np.sum(test2*test2))\n",
    "den = np.sum(np.square(test2-clean_test2_istft_1d))\n",
    "SNR =10*np.log10(num/den)\n",
    "print(\"SNR on test 2 output:\",SNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess1.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
